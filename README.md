#### DSCI691-SP21 Natural Language Processing with Deep Learning Term Project
## Assessing Source Code Functionality with Automatically Generated Text
#### Daniel Schwartz, Yiwen Shi, Aviel Stein, Lu Wang
------
#### Presentation Video
https://youtu.be/jNFoyB4liJ8
#### Project Highlight
Comments are an important tool that developers use to describe their code but are often absent or become out of date as the code changes. Automatically generating comments can be achieved with the Natural Language Processing (NLP) technique called Neural Machine Translation (NMT). To-date, these have shown comparable results with NMT metrics. However, NMT metrics are limited because there is not one specific output that is ground truth (i.e., a phrase in one language may have many "correct" translations in another language). To account for this, we will verify the model's ability to produce functionally descriptive text by classifying the generated text from a program by the program's task. Since a program may have many comments, we will also summarize the comments. As a result, we will have both verified the NMT model and demonstrated how to automatically produce useful in-line documentation for detailed analysis and high-level description for program comprehension.

To predict the functionality of a source code, we will use Google Code Jam (GCJ), which is a coding competition. GCJ has thousands of source code solutions for specific problems, which conveniently creates a parallel dataset by function. This is the data that we will need to build the ML classifier and be the programs we will generate comments for.

This work draws on several active areas of research in NLP as well as their applications to code comprehension. The use of these methods in the smart documentation pipeline and use of resulting text for function classification also offer an alternative for evaluating NMT models. Additionally classification results are less prone to language specific abnormalities that make NMT metrics hard to compare ac cross languages. Additionally the function classification has uses for search and malware detection.

Regarding the NMT model we used, we found that more advanced models are required to capture information from code than from text. We tried several simple seq2seq models that performed adequate for natural language but were not able to produce reliable results for comment generation. Additionally at the time of writing our model is unstable and does not always train well, resulting in a bottle neck in our pipeline that has yet to be resolved. 

Regarding the code segmentation, we found that the BiLSTM presented with a byte-pair encoding tokenizer worked well for segmenting code. It offered several advantages including a sliding window, fuzzy parsing, language agnostic properties, and customizable threshold for more or less granular comments. Sliding window is important for being able to evaluate code long code programs that we encounter in the wild. The fuzzy parsing means we can analyze code even if the it is not correctly written (i.e. contains syntax errors). Since byte-pair encoding is a compression algorithm, it can be easily adapted to work over documents, regardless of language. And finally, we are able to change the value of our threshold for comment insertion to add more or fewer comments we wish.

Due to the time limitation, we didn't use the text classification to evaluate translated comments. We clowned electronics project description of ten different categories from Arduino Project Hub, which is anopen-source electronics prototyping platform. We applied three text summarization methods to the dataset to find out if the summarization will improve the performance of text classification. From the result of our text classification experiment, it showed that the BART summary of project description outperformed the original project description. 

There are many applications of this pipeline, primarily for code comprehension. Several facets of it can be added to and improved upon, and even other features could be used to extend this work. At the time of writing, our NMT model is unstable (as mentioned earlier), building a more stable version and then experimenting with the architecture as well as using the generated text for function classification constitute immediate next steps. The next logical step would be to evaluate repositories (ie several related source code programs), for generating something like a readme file. 

Two other directions for this work focus on the interplay between natural and formal languages and other code qualities beyond logical segment. As discussed in the methods section, our choice of using byte-pair encoding comes with the advantage of being language agnostic and handling fuzzy information. However, what it gives up is the implicit structure in well structured code (ie, the ASTs). Building a model that could learn to predict the AST nodes from tokenized code could help retain that structured information. Also this seems like it would not be difficult to do, as it would essentially be a part of speech tagging task, and we have plenty of high fidelity data at our disposal. This path could also be helpful for fuzzy parsing and error correction. The other direction we mentioned of finding other interesting qualities using the seq2seq and transformer models could be predicting where vulnerabilities are in code, say from diffs in GitHub repositories, and using those diffs to learn before and after such that if you identify a vulnerability, you could suggest a solution. Possibly other layers could be built on top of this as well, such as analyzing the differences in the before and after and describing the difference to explain to the developer. 

#### Code 
1. (`/NMT` folder) Neural Machine Translation models, utilties, and data are in this folder 
2. (`Text_Summarization.ipynb`) Text Summarization (Proof-of-concept with Project Hub data)
run 
3. (`Text_Classification.ipynb`) Text Classification (Proof-of-concept with Project Hub data) 
4. (`Code_Segmentation_utils.ipynb`) Code Snippet data generator, byte-pair python tokenizer, and other code segmentation utility functions
5. (`Code_segmentation_biLSTM`)  Training code segmentation biLSTM modified from Chapter 6